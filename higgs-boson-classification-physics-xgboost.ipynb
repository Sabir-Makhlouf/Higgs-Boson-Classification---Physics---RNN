{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import rcParams\nimport seaborn as sb\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.preprocessing import LabelEncoder,normalize,MinMaxScaler\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix,roc_auc_score,roc_curve\nimport seaborn as sns\n\n\nimport tensorflow as tf","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import tensorflow as tf\n\n# # GPU device Check.\n# device_name = tf.test.gpu_device_name()\n# if device_name == '/device:GPU:0':\n#     print('Found GPU at: {}'.format(device_name))\n# else:\n#     raise SystemError('GPU device not found')\n    \n# import torch\n\n# # If there's a GPU available...\n# if torch.cuda.is_available():    \n\n#     # PyTorch use the GPU.    \n#     device = torch.device(\"cuda\")\n\n#     print('There are %d GPU(s) available.' % torch.cuda.device_count())\n\n#     print('We will use the GPU:', torch.cuda.get_device_name(0))\n\n# # If not...\n# else:\n#     print('No GPU available, using the CPU instead.')\n#     device = torch.device(\"cpu\")","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Reading data\ntrain = pd.read_csv('../input/higgs-boson/training.zip')\ntest = pd.read_csv('../input/higgs-boson/test.zip')\n\nprint(train.shape,test.shape)","execution_count":3,"outputs":[{"output_type":"stream","text":"(250000, 33) (550000, 31)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"        EventId  DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  \\\n0        100000       138.470                       51.655        97.827   \n1        100001       160.937                       68.768       103.235   \n2        100002      -999.000                      162.172       125.953   \n3        100003       143.905                       81.417        80.943   \n4        100004       175.864                       16.915       134.805   \n...         ...           ...                          ...           ...   \n249995   349995      -999.000                       71.989        36.548   \n249996   349996      -999.000                       58.179        68.083   \n249997   349997       105.457                       60.526        75.839   \n249998   349998        94.951                       19.362        68.812   \n249999   349999      -999.000                       72.756        70.831   \n\n        DER_pt_h  DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\n0         27.980                  0.91           124.711                2.666   \n1         48.146               -999.00          -999.000             -999.000   \n2         35.635               -999.00          -999.000             -999.000   \n3          0.414               -999.00          -999.000             -999.000   \n4         16.405               -999.00          -999.000             -999.000   \n...          ...                   ...               ...                  ...   \n249995     5.042               -999.00          -999.000             -999.000   \n249996    22.439               -999.00          -999.000             -999.000   \n249997    39.757               -999.00          -999.000             -999.000   \n249998    13.504               -999.00          -999.000             -999.000   \n249999     7.479               -999.00          -999.000             -999.000   \n\n        DER_deltar_tau_lep  DER_pt_tot  ...  PRI_jet_num  PRI_jet_leading_pt  \\\n0                    3.064      41.928  ...            2              67.435   \n1                    3.473       2.078  ...            1              46.226   \n2                    3.148       9.336  ...            1              44.251   \n3                    3.310       0.414  ...            0            -999.000   \n4                    3.891      16.405  ...            0            -999.000   \n...                    ...         ...  ...          ...                 ...   \n249995               1.392       5.042  ...            0            -999.000   \n249996               2.585      22.439  ...            0            -999.000   \n249997               2.390      22.183  ...            1              41.992   \n249998               3.365      13.504  ...            0            -999.000   \n249999               2.025       7.479  ...            0            -999.000   \n\n        PRI_jet_leading_eta  PRI_jet_leading_phi  PRI_jet_subleading_pt  \\\n0                     2.150                0.444                 46.062   \n1                     0.725                1.158               -999.000   \n2                     2.053               -2.028               -999.000   \n3                  -999.000             -999.000               -999.000   \n4                  -999.000             -999.000               -999.000   \n...                     ...                  ...                    ...   \n249995             -999.000             -999.000               -999.000   \n249996             -999.000             -999.000               -999.000   \n249997                1.800               -0.166               -999.000   \n249998             -999.000             -999.000               -999.000   \n249999             -999.000             -999.000               -999.000   \n\n        PRI_jet_subleading_eta  PRI_jet_subleading_phi  PRI_jet_all_pt  \\\n0                         1.24                  -2.475         113.497   \n1                      -999.00                -999.000          46.226   \n2                      -999.00                -999.000          44.251   \n3                      -999.00                -999.000          -0.000   \n4                      -999.00                -999.000           0.000   \n...                        ...                     ...             ...   \n249995                 -999.00                -999.000           0.000   \n249996                 -999.00                -999.000          -0.000   \n249997                 -999.00                -999.000          41.992   \n249998                 -999.00                -999.000           0.000   \n249999                 -999.00                -999.000           0.000   \n\n          Weight  Label  \n0       0.002653      s  \n1       2.233584      b  \n2       2.347389      b  \n3       5.446378      b  \n4       6.245333      b  \n...          ...    ...  \n249995  4.505083      b  \n249996  2.497259      b  \n249997  0.018636      s  \n249998  1.681611      b  \n249999  1.877474      b  \n\n[250000 rows x 33 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EventId</th>\n      <th>DER_mass_MMC</th>\n      <th>DER_mass_transverse_met_lep</th>\n      <th>DER_mass_vis</th>\n      <th>DER_pt_h</th>\n      <th>DER_deltaeta_jet_jet</th>\n      <th>DER_mass_jet_jet</th>\n      <th>DER_prodeta_jet_jet</th>\n      <th>DER_deltar_tau_lep</th>\n      <th>DER_pt_tot</th>\n      <th>...</th>\n      <th>PRI_jet_num</th>\n      <th>PRI_jet_leading_pt</th>\n      <th>PRI_jet_leading_eta</th>\n      <th>PRI_jet_leading_phi</th>\n      <th>PRI_jet_subleading_pt</th>\n      <th>PRI_jet_subleading_eta</th>\n      <th>PRI_jet_subleading_phi</th>\n      <th>PRI_jet_all_pt</th>\n      <th>Weight</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100000</td>\n      <td>138.470</td>\n      <td>51.655</td>\n      <td>97.827</td>\n      <td>27.980</td>\n      <td>0.91</td>\n      <td>124.711</td>\n      <td>2.666</td>\n      <td>3.064</td>\n      <td>41.928</td>\n      <td>...</td>\n      <td>2</td>\n      <td>67.435</td>\n      <td>2.150</td>\n      <td>0.444</td>\n      <td>46.062</td>\n      <td>1.24</td>\n      <td>-2.475</td>\n      <td>113.497</td>\n      <td>0.002653</td>\n      <td>s</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100001</td>\n      <td>160.937</td>\n      <td>68.768</td>\n      <td>103.235</td>\n      <td>48.146</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>3.473</td>\n      <td>2.078</td>\n      <td>...</td>\n      <td>1</td>\n      <td>46.226</td>\n      <td>0.725</td>\n      <td>1.158</td>\n      <td>-999.000</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>46.226</td>\n      <td>2.233584</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100002</td>\n      <td>-999.000</td>\n      <td>162.172</td>\n      <td>125.953</td>\n      <td>35.635</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>3.148</td>\n      <td>9.336</td>\n      <td>...</td>\n      <td>1</td>\n      <td>44.251</td>\n      <td>2.053</td>\n      <td>-2.028</td>\n      <td>-999.000</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>44.251</td>\n      <td>2.347389</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100003</td>\n      <td>143.905</td>\n      <td>81.417</td>\n      <td>80.943</td>\n      <td>0.414</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>3.310</td>\n      <td>0.414</td>\n      <td>...</td>\n      <td>0</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-0.000</td>\n      <td>5.446378</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100004</td>\n      <td>175.864</td>\n      <td>16.915</td>\n      <td>134.805</td>\n      <td>16.405</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>3.891</td>\n      <td>16.405</td>\n      <td>...</td>\n      <td>0</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>0.000</td>\n      <td>6.245333</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>249995</th>\n      <td>349995</td>\n      <td>-999.000</td>\n      <td>71.989</td>\n      <td>36.548</td>\n      <td>5.042</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>1.392</td>\n      <td>5.042</td>\n      <td>...</td>\n      <td>0</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>0.000</td>\n      <td>4.505083</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>249996</th>\n      <td>349996</td>\n      <td>-999.000</td>\n      <td>58.179</td>\n      <td>68.083</td>\n      <td>22.439</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>2.585</td>\n      <td>22.439</td>\n      <td>...</td>\n      <td>0</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-0.000</td>\n      <td>2.497259</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>249997</th>\n      <td>349997</td>\n      <td>105.457</td>\n      <td>60.526</td>\n      <td>75.839</td>\n      <td>39.757</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>2.390</td>\n      <td>22.183</td>\n      <td>...</td>\n      <td>1</td>\n      <td>41.992</td>\n      <td>1.800</td>\n      <td>-0.166</td>\n      <td>-999.000</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>41.992</td>\n      <td>0.018636</td>\n      <td>s</td>\n    </tr>\n    <tr>\n      <th>249998</th>\n      <td>349998</td>\n      <td>94.951</td>\n      <td>19.362</td>\n      <td>68.812</td>\n      <td>13.504</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>3.365</td>\n      <td>13.504</td>\n      <td>...</td>\n      <td>0</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>0.000</td>\n      <td>1.681611</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>249999</th>\n      <td>349999</td>\n      <td>-999.000</td>\n      <td>72.756</td>\n      <td>70.831</td>\n      <td>7.479</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>2.025</td>\n      <td>7.479</td>\n      <td>...</td>\n      <td>0</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>0.000</td>\n      <td>1.877474</td>\n      <td>b</td>\n    </tr>\n  </tbody>\n</table>\n<p>250000 rows × 33 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.columns.values,'\\n')\nprint(test.columns.values)","execution_count":5,"outputs":[{"output_type":"stream","text":"['EventId' 'DER_mass_MMC' 'DER_mass_transverse_met_lep' 'DER_mass_vis'\n 'DER_pt_h' 'DER_deltaeta_jet_jet' 'DER_mass_jet_jet'\n 'DER_prodeta_jet_jet' 'DER_deltar_tau_lep' 'DER_pt_tot' 'DER_sum_pt'\n 'DER_pt_ratio_lep_tau' 'DER_met_phi_centrality' 'DER_lep_eta_centrality'\n 'PRI_tau_pt' 'PRI_tau_eta' 'PRI_tau_phi' 'PRI_lep_pt' 'PRI_lep_eta'\n 'PRI_lep_phi' 'PRI_met' 'PRI_met_phi' 'PRI_met_sumet' 'PRI_jet_num'\n 'PRI_jet_leading_pt' 'PRI_jet_leading_eta' 'PRI_jet_leading_phi'\n 'PRI_jet_subleading_pt' 'PRI_jet_subleading_eta' 'PRI_jet_subleading_phi'\n 'PRI_jet_all_pt' 'Weight' 'Label'] \n\n['EventId' 'DER_mass_MMC' 'DER_mass_transverse_met_lep' 'DER_mass_vis'\n 'DER_pt_h' 'DER_deltaeta_jet_jet' 'DER_mass_jet_jet'\n 'DER_prodeta_jet_jet' 'DER_deltar_tau_lep' 'DER_pt_tot' 'DER_sum_pt'\n 'DER_pt_ratio_lep_tau' 'DER_met_phi_centrality' 'DER_lep_eta_centrality'\n 'PRI_tau_pt' 'PRI_tau_eta' 'PRI_tau_phi' 'PRI_lep_pt' 'PRI_lep_eta'\n 'PRI_lep_phi' 'PRI_met' 'PRI_met_phi' 'PRI_met_sumet' 'PRI_jet_num'\n 'PRI_jet_leading_pt' 'PRI_jet_leading_eta' 'PRI_jet_leading_phi'\n 'PRI_jet_subleading_pt' 'PRI_jet_subleading_eta' 'PRI_jet_subleading_phi'\n 'PRI_jet_all_pt']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(['Weight'], axis=1)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train['Label'].value_counts())\n\nrcParams['figure.figsize'] = 10,5\nsb.barplot(x = train['Label'].value_counts().index, y = train['Label'].value_counts().values)\nplt.title('Label counts')\nplt.show()","execution_count":7,"outputs":[{"output_type":"stream","text":"b    164333\ns     85667\nName: Label, dtype: int64\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x360 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting dummy variables column\n\nenc = LabelEncoder()\n\ntrain['Label'] = enc.fit_transform(train['Label'])\ntrain.head()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"   EventId  DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  DER_pt_h  \\\n0   100000       138.470                       51.655        97.827    27.980   \n1   100001       160.937                       68.768       103.235    48.146   \n2   100002      -999.000                      162.172       125.953    35.635   \n3   100003       143.905                       81.417        80.943     0.414   \n4   100004       175.864                       16.915       134.805    16.405   \n\n   DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\n0                  0.91           124.711                2.666   \n1               -999.00          -999.000             -999.000   \n2               -999.00          -999.000             -999.000   \n3               -999.00          -999.000             -999.000   \n4               -999.00          -999.000             -999.000   \n\n   DER_deltar_tau_lep  DER_pt_tot  ...  PRI_met_sumet  PRI_jet_num  \\\n0               3.064      41.928  ...        258.733            2   \n1               3.473       2.078  ...        164.546            1   \n2               3.148       9.336  ...        260.414            1   \n3               3.310       0.414  ...         86.062            0   \n4               3.891      16.405  ...         53.131            0   \n\n   PRI_jet_leading_pt  PRI_jet_leading_eta  PRI_jet_leading_phi  \\\n0              67.435                2.150                0.444   \n1              46.226                0.725                1.158   \n2              44.251                2.053               -2.028   \n3            -999.000             -999.000             -999.000   \n4            -999.000             -999.000             -999.000   \n\n   PRI_jet_subleading_pt  PRI_jet_subleading_eta  PRI_jet_subleading_phi  \\\n0                 46.062                    1.24                  -2.475   \n1               -999.000                 -999.00                -999.000   \n2               -999.000                 -999.00                -999.000   \n3               -999.000                 -999.00                -999.000   \n4               -999.000                 -999.00                -999.000   \n\n   PRI_jet_all_pt  Label  \n0         113.497      1  \n1          46.226      0  \n2          44.251      0  \n3          -0.000      0  \n4           0.000      0  \n\n[5 rows x 32 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EventId</th>\n      <th>DER_mass_MMC</th>\n      <th>DER_mass_transverse_met_lep</th>\n      <th>DER_mass_vis</th>\n      <th>DER_pt_h</th>\n      <th>DER_deltaeta_jet_jet</th>\n      <th>DER_mass_jet_jet</th>\n      <th>DER_prodeta_jet_jet</th>\n      <th>DER_deltar_tau_lep</th>\n      <th>DER_pt_tot</th>\n      <th>...</th>\n      <th>PRI_met_sumet</th>\n      <th>PRI_jet_num</th>\n      <th>PRI_jet_leading_pt</th>\n      <th>PRI_jet_leading_eta</th>\n      <th>PRI_jet_leading_phi</th>\n      <th>PRI_jet_subleading_pt</th>\n      <th>PRI_jet_subleading_eta</th>\n      <th>PRI_jet_subleading_phi</th>\n      <th>PRI_jet_all_pt</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100000</td>\n      <td>138.470</td>\n      <td>51.655</td>\n      <td>97.827</td>\n      <td>27.980</td>\n      <td>0.91</td>\n      <td>124.711</td>\n      <td>2.666</td>\n      <td>3.064</td>\n      <td>41.928</td>\n      <td>...</td>\n      <td>258.733</td>\n      <td>2</td>\n      <td>67.435</td>\n      <td>2.150</td>\n      <td>0.444</td>\n      <td>46.062</td>\n      <td>1.24</td>\n      <td>-2.475</td>\n      <td>113.497</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100001</td>\n      <td>160.937</td>\n      <td>68.768</td>\n      <td>103.235</td>\n      <td>48.146</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>3.473</td>\n      <td>2.078</td>\n      <td>...</td>\n      <td>164.546</td>\n      <td>1</td>\n      <td>46.226</td>\n      <td>0.725</td>\n      <td>1.158</td>\n      <td>-999.000</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>46.226</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100002</td>\n      <td>-999.000</td>\n      <td>162.172</td>\n      <td>125.953</td>\n      <td>35.635</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>3.148</td>\n      <td>9.336</td>\n      <td>...</td>\n      <td>260.414</td>\n      <td>1</td>\n      <td>44.251</td>\n      <td>2.053</td>\n      <td>-2.028</td>\n      <td>-999.000</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>44.251</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100003</td>\n      <td>143.905</td>\n      <td>81.417</td>\n      <td>80.943</td>\n      <td>0.414</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>3.310</td>\n      <td>0.414</td>\n      <td>...</td>\n      <td>86.062</td>\n      <td>0</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-0.000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100004</td>\n      <td>175.864</td>\n      <td>16.915</td>\n      <td>134.805</td>\n      <td>16.405</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>3.891</td>\n      <td>16.405</td>\n      <td>...</td>\n      <td>53.131</td>\n      <td>0</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>0.000</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 32 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train[\"Label\"]\nX = train\nX_test = test","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.set_index(['EventId'],inplace = True)\nX_test.set_index(['EventId'],inplace = True)\nX = X.drop(['Label'], axis=1)\n\nX.head()","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"         DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  DER_pt_h  \\\nEventId                                                                      \n100000        138.470                       51.655        97.827    27.980   \n100001        160.937                       68.768       103.235    48.146   \n100002       -999.000                      162.172       125.953    35.635   \n100003        143.905                       81.417        80.943     0.414   \n100004        175.864                       16.915       134.805    16.405   \n\n         DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\nEventId                                                                \n100000                   0.91           124.711                2.666   \n100001                -999.00          -999.000             -999.000   \n100002                -999.00          -999.000             -999.000   \n100003                -999.00          -999.000             -999.000   \n100004                -999.00          -999.000             -999.000   \n\n         DER_deltar_tau_lep  DER_pt_tot  DER_sum_pt  ...  PRI_met_phi  \\\nEventId                                              ...                \n100000                3.064      41.928     197.760  ...       -0.277   \n100001                3.473       2.078     125.157  ...       -1.916   \n100002                3.148       9.336     197.814  ...       -2.186   \n100003                3.310       0.414      75.968  ...        0.060   \n100004                3.891      16.405      57.983  ...       -0.871   \n\n         PRI_met_sumet  PRI_jet_num  PRI_jet_leading_pt  PRI_jet_leading_eta  \\\nEventId                                                                        \n100000         258.733            2              67.435                2.150   \n100001         164.546            1              46.226                0.725   \n100002         260.414            1              44.251                2.053   \n100003          86.062            0            -999.000             -999.000   \n100004          53.131            0            -999.000             -999.000   \n\n         PRI_jet_leading_phi  PRI_jet_subleading_pt  PRI_jet_subleading_eta  \\\nEventId                                                                       \n100000                 0.444                 46.062                    1.24   \n100001                 1.158               -999.000                 -999.00   \n100002                -2.028               -999.000                 -999.00   \n100003              -999.000               -999.000                 -999.00   \n100004              -999.000               -999.000                 -999.00   \n\n         PRI_jet_subleading_phi  PRI_jet_all_pt  \nEventId                                          \n100000                   -2.475         113.497  \n100001                 -999.000          46.226  \n100002                 -999.000          44.251  \n100003                 -999.000          -0.000  \n100004                 -999.000           0.000  \n\n[5 rows x 30 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DER_mass_MMC</th>\n      <th>DER_mass_transverse_met_lep</th>\n      <th>DER_mass_vis</th>\n      <th>DER_pt_h</th>\n      <th>DER_deltaeta_jet_jet</th>\n      <th>DER_mass_jet_jet</th>\n      <th>DER_prodeta_jet_jet</th>\n      <th>DER_deltar_tau_lep</th>\n      <th>DER_pt_tot</th>\n      <th>DER_sum_pt</th>\n      <th>...</th>\n      <th>PRI_met_phi</th>\n      <th>PRI_met_sumet</th>\n      <th>PRI_jet_num</th>\n      <th>PRI_jet_leading_pt</th>\n      <th>PRI_jet_leading_eta</th>\n      <th>PRI_jet_leading_phi</th>\n      <th>PRI_jet_subleading_pt</th>\n      <th>PRI_jet_subleading_eta</th>\n      <th>PRI_jet_subleading_phi</th>\n      <th>PRI_jet_all_pt</th>\n    </tr>\n    <tr>\n      <th>EventId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>100000</th>\n      <td>138.470</td>\n      <td>51.655</td>\n      <td>97.827</td>\n      <td>27.980</td>\n      <td>0.91</td>\n      <td>124.711</td>\n      <td>2.666</td>\n      <td>3.064</td>\n      <td>41.928</td>\n      <td>197.760</td>\n      <td>...</td>\n      <td>-0.277</td>\n      <td>258.733</td>\n      <td>2</td>\n      <td>67.435</td>\n      <td>2.150</td>\n      <td>0.444</td>\n      <td>46.062</td>\n      <td>1.24</td>\n      <td>-2.475</td>\n      <td>113.497</td>\n    </tr>\n    <tr>\n      <th>100001</th>\n      <td>160.937</td>\n      <td>68.768</td>\n      <td>103.235</td>\n      <td>48.146</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>3.473</td>\n      <td>2.078</td>\n      <td>125.157</td>\n      <td>...</td>\n      <td>-1.916</td>\n      <td>164.546</td>\n      <td>1</td>\n      <td>46.226</td>\n      <td>0.725</td>\n      <td>1.158</td>\n      <td>-999.000</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>46.226</td>\n    </tr>\n    <tr>\n      <th>100002</th>\n      <td>-999.000</td>\n      <td>162.172</td>\n      <td>125.953</td>\n      <td>35.635</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>3.148</td>\n      <td>9.336</td>\n      <td>197.814</td>\n      <td>...</td>\n      <td>-2.186</td>\n      <td>260.414</td>\n      <td>1</td>\n      <td>44.251</td>\n      <td>2.053</td>\n      <td>-2.028</td>\n      <td>-999.000</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>44.251</td>\n    </tr>\n    <tr>\n      <th>100003</th>\n      <td>143.905</td>\n      <td>81.417</td>\n      <td>80.943</td>\n      <td>0.414</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>3.310</td>\n      <td>0.414</td>\n      <td>75.968</td>\n      <td>...</td>\n      <td>0.060</td>\n      <td>86.062</td>\n      <td>0</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-0.000</td>\n    </tr>\n    <tr>\n      <th>100004</th>\n      <td>175.864</td>\n      <td>16.915</td>\n      <td>134.805</td>\n      <td>16.405</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>3.891</td>\n      <td>16.405</td>\n      <td>57.983</td>\n      <td>...</td>\n      <td>-0.871</td>\n      <td>53.131</td>\n      <td>0</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.00</td>\n      <td>-999.000</td>\n      <td>0.000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.head()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"         DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  DER_pt_h  \\\nEventId                                                                      \n350000       -999.000                       79.589        23.916     3.036   \n350001        106.398                       67.490        87.949    49.994   \n350002        117.794                       56.226        96.358     4.137   \n350003        135.861                       30.604        97.288     9.104   \n350004         74.159                       82.772        58.731    89.646   \n\n         DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\nEventId                                                                \n350000               -999.000          -999.000             -999.000   \n350001               -999.000          -999.000             -999.000   \n350002               -999.000          -999.000             -999.000   \n350003               -999.000          -999.000             -999.000   \n350004                  1.347           536.663               -0.339   \n\n         DER_deltar_tau_lep  DER_pt_tot  DER_sum_pt  ...  PRI_met_phi  \\\nEventId                                              ...                \n350000                0.903       3.036      56.018  ...        2.022   \n350001                2.048       2.679     132.865  ...       -1.138   \n350002                2.755       4.137      97.600  ...       -1.868   \n350003                2.811       9.104      94.112  ...        1.172   \n350004                1.028      77.213     721.552  ...       -0.231   \n\n         PRI_met_sumet  PRI_jet_num  PRI_jet_leading_pt  PRI_jet_leading_eta  \\\nEventId                                                                        \n350000          98.556            0            -999.000             -999.000   \n350001         176.251            1              47.575               -0.553   \n350002         111.505            0            -999.000             -999.000   \n350003         164.707            0            -999.000             -999.000   \n350004         869.614            3             254.085               -1.013   \n\n         PRI_jet_leading_phi  PRI_jet_subleading_pt  PRI_jet_subleading_eta  \\\nEventId                                                                       \n350000              -999.000               -999.000                -999.000   \n350001                -0.849               -999.000                -999.000   \n350002              -999.000               -999.000                -999.000   \n350003              -999.000               -999.000                -999.000   \n350004                -0.334                185.857                   0.335   \n\n         PRI_jet_subleading_phi  PRI_jet_all_pt  \nEventId                                          \n350000                 -999.000          -0.000  \n350001                 -999.000          47.575  \n350002                 -999.000           0.000  \n350003                 -999.000           0.000  \n350004                    2.587         599.213  \n\n[5 rows x 30 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DER_mass_MMC</th>\n      <th>DER_mass_transverse_met_lep</th>\n      <th>DER_mass_vis</th>\n      <th>DER_pt_h</th>\n      <th>DER_deltaeta_jet_jet</th>\n      <th>DER_mass_jet_jet</th>\n      <th>DER_prodeta_jet_jet</th>\n      <th>DER_deltar_tau_lep</th>\n      <th>DER_pt_tot</th>\n      <th>DER_sum_pt</th>\n      <th>...</th>\n      <th>PRI_met_phi</th>\n      <th>PRI_met_sumet</th>\n      <th>PRI_jet_num</th>\n      <th>PRI_jet_leading_pt</th>\n      <th>PRI_jet_leading_eta</th>\n      <th>PRI_jet_leading_phi</th>\n      <th>PRI_jet_subleading_pt</th>\n      <th>PRI_jet_subleading_eta</th>\n      <th>PRI_jet_subleading_phi</th>\n      <th>PRI_jet_all_pt</th>\n    </tr>\n    <tr>\n      <th>EventId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>350000</th>\n      <td>-999.000</td>\n      <td>79.589</td>\n      <td>23.916</td>\n      <td>3.036</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>0.903</td>\n      <td>3.036</td>\n      <td>56.018</td>\n      <td>...</td>\n      <td>2.022</td>\n      <td>98.556</td>\n      <td>0</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-0.000</td>\n    </tr>\n    <tr>\n      <th>350001</th>\n      <td>106.398</td>\n      <td>67.490</td>\n      <td>87.949</td>\n      <td>49.994</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>2.048</td>\n      <td>2.679</td>\n      <td>132.865</td>\n      <td>...</td>\n      <td>-1.138</td>\n      <td>176.251</td>\n      <td>1</td>\n      <td>47.575</td>\n      <td>-0.553</td>\n      <td>-0.849</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>47.575</td>\n    </tr>\n    <tr>\n      <th>350002</th>\n      <td>117.794</td>\n      <td>56.226</td>\n      <td>96.358</td>\n      <td>4.137</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>2.755</td>\n      <td>4.137</td>\n      <td>97.600</td>\n      <td>...</td>\n      <td>-1.868</td>\n      <td>111.505</td>\n      <td>0</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>350003</th>\n      <td>135.861</td>\n      <td>30.604</td>\n      <td>97.288</td>\n      <td>9.104</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>2.811</td>\n      <td>9.104</td>\n      <td>94.112</td>\n      <td>...</td>\n      <td>1.172</td>\n      <td>164.707</td>\n      <td>0</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>-999.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>350004</th>\n      <td>74.159</td>\n      <td>82.772</td>\n      <td>58.731</td>\n      <td>89.646</td>\n      <td>1.347</td>\n      <td>536.663</td>\n      <td>-0.339</td>\n      <td>1.028</td>\n      <td>77.213</td>\n      <td>721.552</td>\n      <td>...</td>\n      <td>-0.231</td>\n      <td>869.614</td>\n      <td>3</td>\n      <td>254.085</td>\n      <td>-1.013</td>\n      <td>-0.334</td>\n      <td>185.857</td>\n      <td>0.335</td>\n      <td>2.587</td>\n      <td>599.213</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"        DER_mass_MMC  DER_mass_transverse_met_lep   DER_mass_vis  \\\ncount  250000.000000                250000.000000  250000.000000   \nmean      -49.023079                    49.239819      81.181982   \nstd       406.345647                    35.344886      40.828691   \nmin      -999.000000                     0.000000       6.329000   \n25%        78.100750                    19.241000      59.388750   \n50%       105.012000                    46.524000      73.752000   \n75%       130.606250                    73.598000      92.259000   \nmax      1192.026000                   690.075000    1349.351000   \n\n            DER_pt_h  DER_deltaeta_jet_jet  DER_mass_jet_jet  \\\ncount  250000.000000         250000.000000     250000.000000   \nmean       57.895962           -708.420675       -601.237051   \nstd        63.655682            454.480565        657.972302   \nmin         0.000000           -999.000000       -999.000000   \n25%        14.068750           -999.000000       -999.000000   \n50%        38.467500           -999.000000       -999.000000   \n75%        79.169000              0.490000         83.446000   \nmax      2834.999000              8.503000       4974.979000   \n\n       DER_prodeta_jet_jet  DER_deltar_tau_lep     DER_pt_tot     DER_sum_pt  \\\ncount        250000.000000       250000.000000  250000.000000  250000.000000   \nmean           -709.356603            2.373100      18.917332     158.432217   \nstd             453.019877            0.782911      22.273494     115.706115   \nmin            -999.000000            0.208000       0.000000      46.104000   \n25%            -999.000000            1.810000       2.841000      77.550000   \n50%            -999.000000            2.491500      12.315500     120.664500   \n75%              -4.593000            2.961000      27.591000     200.478250   \nmax              16.690000            5.684000    2834.999000    1852.462000   \n\n       ...  PRI_met_sumet    PRI_jet_num  PRI_jet_leading_pt  \\\ncount  ...  250000.000000  250000.000000       250000.000000   \nmean   ...     209.797178       0.979176         -348.329567   \nstd    ...     126.499506       0.977426          532.962789   \nmin    ...      13.678000       0.000000         -999.000000   \n25%    ...     123.017500       0.000000         -999.000000   \n50%    ...     179.739000       1.000000           38.960000   \n75%    ...     263.379250       2.000000           75.349000   \nmax    ...    2003.976000       3.000000         1120.573000   \n\n       PRI_jet_leading_eta  PRI_jet_leading_phi  PRI_jet_subleading_pt  \\\ncount        250000.000000        250000.000000          250000.000000   \nmean           -399.254314          -399.259788            -692.381204   \nstd             489.338286           489.333883             479.875496   \nmin            -999.000000          -999.000000            -999.000000   \n25%            -999.000000          -999.000000            -999.000000   \n50%              -1.872000            -2.093000            -999.000000   \n75%               0.433000             0.503000              33.703000   \nmax               4.499000             3.141000             721.456000   \n\n       PRI_jet_subleading_eta  PRI_jet_subleading_phi  PRI_jet_all_pt  \\\ncount           250000.000000           250000.000000   250000.000000   \nmean              -709.121609             -709.118631       73.064591   \nstd                453.384624              453.389017       98.015662   \nmin               -999.000000             -999.000000        0.000000   \n25%               -999.000000             -999.000000        0.000000   \n50%               -999.000000             -999.000000       40.512500   \n75%                 -2.457000               -2.275000      109.933750   \nmax                  4.500000                3.142000     1633.433000   \n\n               Label  \ncount  250000.000000  \nmean        0.342668  \nstd         0.474603  \nmin         0.000000  \n25%         0.000000  \n50%         0.000000  \n75%         1.000000  \nmax         1.000000  \n\n[8 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DER_mass_MMC</th>\n      <th>DER_mass_transverse_met_lep</th>\n      <th>DER_mass_vis</th>\n      <th>DER_pt_h</th>\n      <th>DER_deltaeta_jet_jet</th>\n      <th>DER_mass_jet_jet</th>\n      <th>DER_prodeta_jet_jet</th>\n      <th>DER_deltar_tau_lep</th>\n      <th>DER_pt_tot</th>\n      <th>DER_sum_pt</th>\n      <th>...</th>\n      <th>PRI_met_sumet</th>\n      <th>PRI_jet_num</th>\n      <th>PRI_jet_leading_pt</th>\n      <th>PRI_jet_leading_eta</th>\n      <th>PRI_jet_leading_phi</th>\n      <th>PRI_jet_subleading_pt</th>\n      <th>PRI_jet_subleading_eta</th>\n      <th>PRI_jet_subleading_phi</th>\n      <th>PRI_jet_all_pt</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>...</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n      <td>250000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>-49.023079</td>\n      <td>49.239819</td>\n      <td>81.181982</td>\n      <td>57.895962</td>\n      <td>-708.420675</td>\n      <td>-601.237051</td>\n      <td>-709.356603</td>\n      <td>2.373100</td>\n      <td>18.917332</td>\n      <td>158.432217</td>\n      <td>...</td>\n      <td>209.797178</td>\n      <td>0.979176</td>\n      <td>-348.329567</td>\n      <td>-399.254314</td>\n      <td>-399.259788</td>\n      <td>-692.381204</td>\n      <td>-709.121609</td>\n      <td>-709.118631</td>\n      <td>73.064591</td>\n      <td>0.342668</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>406.345647</td>\n      <td>35.344886</td>\n      <td>40.828691</td>\n      <td>63.655682</td>\n      <td>454.480565</td>\n      <td>657.972302</td>\n      <td>453.019877</td>\n      <td>0.782911</td>\n      <td>22.273494</td>\n      <td>115.706115</td>\n      <td>...</td>\n      <td>126.499506</td>\n      <td>0.977426</td>\n      <td>532.962789</td>\n      <td>489.338286</td>\n      <td>489.333883</td>\n      <td>479.875496</td>\n      <td>453.384624</td>\n      <td>453.389017</td>\n      <td>98.015662</td>\n      <td>0.474603</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-999.000000</td>\n      <td>0.000000</td>\n      <td>6.329000</td>\n      <td>0.000000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>0.208000</td>\n      <td>0.000000</td>\n      <td>46.104000</td>\n      <td>...</td>\n      <td>13.678000</td>\n      <td>0.000000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>78.100750</td>\n      <td>19.241000</td>\n      <td>59.388750</td>\n      <td>14.068750</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>1.810000</td>\n      <td>2.841000</td>\n      <td>77.550000</td>\n      <td>...</td>\n      <td>123.017500</td>\n      <td>0.000000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>105.012000</td>\n      <td>46.524000</td>\n      <td>73.752000</td>\n      <td>38.467500</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>2.491500</td>\n      <td>12.315500</td>\n      <td>120.664500</td>\n      <td>...</td>\n      <td>179.739000</td>\n      <td>1.000000</td>\n      <td>38.960000</td>\n      <td>-1.872000</td>\n      <td>-2.093000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>-999.000000</td>\n      <td>40.512500</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>130.606250</td>\n      <td>73.598000</td>\n      <td>92.259000</td>\n      <td>79.169000</td>\n      <td>0.490000</td>\n      <td>83.446000</td>\n      <td>-4.593000</td>\n      <td>2.961000</td>\n      <td>27.591000</td>\n      <td>200.478250</td>\n      <td>...</td>\n      <td>263.379250</td>\n      <td>2.000000</td>\n      <td>75.349000</td>\n      <td>0.433000</td>\n      <td>0.503000</td>\n      <td>33.703000</td>\n      <td>-2.457000</td>\n      <td>-2.275000</td>\n      <td>109.933750</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1192.026000</td>\n      <td>690.075000</td>\n      <td>1349.351000</td>\n      <td>2834.999000</td>\n      <td>8.503000</td>\n      <td>4974.979000</td>\n      <td>16.690000</td>\n      <td>5.684000</td>\n      <td>2834.999000</td>\n      <td>1852.462000</td>\n      <td>...</td>\n      <td>2003.976000</td>\n      <td>3.000000</td>\n      <td>1120.573000</td>\n      <td>4.499000</td>\n      <td>3.141000</td>\n      <td>721.456000</td>\n      <td>4.500000</td>\n      <td>3.142000</td>\n      <td>1633.433000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 31 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Normalizing\n\nfrom sklearn.preprocessing import normalize\n\nX = normalize(X)\nX_test = normalize(X_test)","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1-DNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import StratifiedKFold\n# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, GlobalAveragePooling2D,Activation, BatchNormalization\n# from tensorflow.keras.models import Sequential\n\n# BATCH_SIZE = 8\n# n_fold = 5\n\n# kfold = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\n# cvscores = []  \n# for train, test in kfold.split(X, y): \n#   # create model \n#     model = Sequential() \n#     model.add(Dense(1024, input_dim=30, activation='relu'))\n#     model.add(Dropout(0.8)) \n#     model.add(Dense(1024, activation='relu')) \n#     model.add(Dropout(0.8)) \n#     model.add(Dense(512, activation='relu')) \n#     model.add(Dropout(0.8)) \n#     model.add(Dense(2,activation='softmax'))\n#     # Compile model\n#     opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.01, amsgrad=False)\n#     model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n#     # Fit the model\n#     model.fit(X[train], y[train],validation_data=(X[train], y[train]), epochs=10, batch_size=BATCH_SIZE, verbose=0)\n#     # evaluate the model\n#     scores = model.evaluate(X[test], y[test], verbose=0)\n#     print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n#     cvscores.append(scores[1] * 100) \n      \n#     #prediction     \n#     prediction = model.predict(X_test, batch_size=BATCH_SIZE, verbose=0)   \n    \n# print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores))) ","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2- XGB"},{"metadata":{"trusted":true},"cell_type":"code","source":"#K Fold Cross Validation\n\nfrom sklearn.model_selection import KFold\n\n\nkf = KFold(n_splits=5, random_state=2020, shuffle=True)\n\nfor train_index, val_index in kf.split(X):\n    print(\"TRAIN:\", train_index, \"TEST:\", val_index)\n    X_train, X_val = X[train_index], X[val_index]\n    y_train, y_val = y[train_index], y[val_index]","execution_count":15,"outputs":[{"output_type":"stream","text":"TRAIN: [     0      1      2 ... 249996 249997 249998] TEST: [     3     15     16 ... 249966 249972 249999]\nTRAIN: [     1      2      3 ... 249997 249998 249999] TEST: [     0      4     11 ... 249986 249991 249992]\nTRAIN: [     0      1      3 ... 249995 249998 249999] TEST: [     2      5      7 ... 249994 249996 249997]\nTRAIN: [     0      2      3 ... 249997 249998 249999] TEST: [     1     13     14 ... 249981 249985 249990]\nTRAIN: [     0      1      2 ... 249996 249997 249999] TEST: [     6      9     20 ... 249993 249995 249998]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import xgboost as xgb\n\n# dtrain = xgb.DMatrix(X_train, label=y_train)\n# dvalid = xgb.DMatrix(X_val, label=y_val)\n# watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n\n# xgb_pars = {'min_child_weight': 100, 'eta': 0.04, 'colsample_bytree': 0.8, 'max_depth': 100,\n#             'subsample': 0.75, 'lambda': 2, 'nthread': -1, 'booster' : 'gbtree', 'silent': 1, 'gamma' : 0,\n#             'eval_metric': 'rmse', 'objective': 'reg:linear'}    \n\n# model = xgb.train(xgb_pars, dtrain, 500, watchlist, early_stopping_rounds=250,\n#                   maximize=False, verbose_eval=15) ","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dtest = xgb.DMatrix(X_test)\n\n# prediction = model.predict(dtest)  ","execution_count":17,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3-RNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_val.shape)\nprint(y_val.shape)","execution_count":18,"outputs":[{"output_type":"stream","text":"(200000, 30)\n(200000,)\n(50000, 30)\n(50000,)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reshape for rnn\n\nX_train = X_train.reshape(-1, 1, 30)\nX_val  = X_val.reshape(-1, 1, 30)\ny_train = y_train.values #convert pd to array\ny_train = y_train.reshape(-1, 1,)\ny_val = y_val.values #convert pd to array\ny_val = y_val.reshape(-1, 1,)","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"(200000, 1, 30)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Conv2D,LSTM,LeakyReLU, MaxPooling2D,Concatenate,Input, Dropout, Flatten, Dense, GlobalAveragePooling2D,Activation, BatchNormalization\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.models import Model\n\n\n  # create model\n    \n\n#input \ninput_layer = Input(shape=(1,30))\nmain_rnn_layer = LSTM(64, return_sequences=True, recurrent_dropout=0.2)(input_layer)\n\n    \n#output\nrnn = LSTM(32)(main_rnn_layer)\ndense = Dense(128)(rnn)\ndropout_c = Dropout(0.3)(dense)\nclasses = Dense(1, activation= LeakyReLU(alpha=0.1),name=\"class\")(dropout_c)\n\nmodel = Model(input_layer, classes)\n\n# Compile model\ncallbacks = [ReduceLROnPlateau(monitor='val_loss', patience=4, verbose=1, factor=0.6),\n             EarlyStopping(monitor='val_loss', patience=20),\n             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\nmodel.compile(loss=[tf.keras.losses.MeanSquaredLogarithmicError(),tf.keras.losses.MeanSquaredLogarithmicError()], optimizer=\"adam\")\n\n\nmodel.summary()\n# Fit the model\nhistory = model.fit(X_train, y_train, \n          epochs = 250, \n          batch_size = 16, \n          validation_data=(X_val,  y_val), \n          callbacks=callbacks)\n","execution_count":20,"outputs":[{"output_type":"stream","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 1, 30)]           0         \n_________________________________________________________________\nlstm (LSTM)                  (None, 1, 64)             24320     \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 32)                12416     \n_________________________________________________________________\ndense (Dense)                (None, 128)               4224      \n_________________________________________________________________\ndropout (Dropout)            (None, 128)               0         \n_________________________________________________________________\nclass (Dense)                (None, 1)                 129       \n=================================================================\nTotal params: 41,089\nTrainable params: 41,089\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/250\n12500/12500 [==============================] - 69s 6ms/step - loss: 0.0854 - val_loss: 0.0797 - lr: 0.0010\nEpoch 2/250\n12500/12500 [==============================] - 67s 5ms/step - loss: 0.0777 - val_loss: 0.0787 - lr: 0.0010\nEpoch 3/250\n12500/12500 [==============================] - 69s 6ms/step - loss: 0.0710 - val_loss: 0.0688 - lr: 0.0010\nEpoch 4/250\n12500/12500 [==============================] - 67s 5ms/step - loss: 0.0692 - val_loss: 0.0699 - lr: 0.0010\nEpoch 5/250\n12500/12500 [==============================] - 66s 5ms/step - loss: 0.0681 - val_loss: 0.0676 - lr: 0.0010\nEpoch 6/250\n12500/12500 [==============================] - 66s 5ms/step - loss: 0.0670 - val_loss: 0.0661 - lr: 0.0010\nEpoch 7/250\n12500/12500 [==============================] - 64s 5ms/step - loss: 0.0658 - val_loss: 0.0647 - lr: 0.0010\nEpoch 8/250\n12500/12500 [==============================] - 64s 5ms/step - loss: 0.0648 - val_loss: 0.0655 - lr: 0.0010\nEpoch 9/250\n12500/12500 [==============================] - 63s 5ms/step - loss: 0.0639 - val_loss: 0.0624 - lr: 0.0010\nEpoch 10/250\n12500/12500 [==============================] - 63s 5ms/step - loss: 0.0634 - val_loss: 0.0624 - lr: 0.0010\nEpoch 11/250\n12500/12500 [==============================] - 65s 5ms/step - loss: 0.0629 - val_loss: 0.0613 - lr: 0.0010\nEpoch 12/250\n12500/12500 [==============================] - 64s 5ms/step - loss: 0.0626 - val_loss: 0.0633 - lr: 0.0010\nEpoch 13/250\n12500/12500 [==============================] - 65s 5ms/step - loss: 0.0624 - val_loss: 0.0610 - lr: 0.0010\nEpoch 14/250\n12500/12500 [==============================] - 65s 5ms/step - loss: 0.0620 - val_loss: 0.0611 - lr: 0.0010\nEpoch 15/250\n12500/12500 [==============================] - 65s 5ms/step - loss: 0.0617 - val_loss: 0.0652 - lr: 0.0010\nEpoch 16/250\n12500/12500 [==============================] - 63s 5ms/step - loss: 0.0616 - val_loss: 0.0599 - lr: 0.0010\nEpoch 17/250\n12500/12500 [==============================] - 67s 5ms/step - loss: 0.0614 - val_loss: 0.0600 - lr: 0.0010\nEpoch 18/250\n12500/12500 [==============================] - 66s 5ms/step - loss: 0.0612 - val_loss: 0.0602 - lr: 0.0010\nEpoch 19/250\n12500/12500 [==============================] - 65s 5ms/step - loss: 0.0611 - val_loss: 0.0609 - lr: 0.0010\nEpoch 20/250\n12489/12500 [============================>.] - ETA: 0s - loss: 0.0609\nEpoch 00020: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n12500/12500 [==============================] - 65s 5ms/step - loss: 0.0609 - val_loss: 0.0601 - lr: 0.0010\nEpoch 21/250\n12500/12500 [==============================] - 63s 5ms/step - loss: 0.0597 - val_loss: 0.0588 - lr: 6.0000e-04\nEpoch 22/250\n12500/12500 [==============================] - 64s 5ms/step - loss: 0.0597 - val_loss: 0.0611 - lr: 6.0000e-04\nEpoch 23/250\n12500/12500 [==============================] - 64s 5ms/step - loss: 0.0596 - val_loss: 0.0591 - lr: 6.0000e-04\nEpoch 24/250\n12500/12500 [==============================] - 65s 5ms/step - loss: 0.0595 - val_loss: 0.0593 - lr: 6.0000e-04\nEpoch 25/250\n12500/12500 [==============================] - 66s 5ms/step - loss: 0.0595 - val_loss: 0.0585 - lr: 6.0000e-04\nEpoch 26/250\n12500/12500 [==============================] - 65s 5ms/step - loss: 0.0595 - val_loss: 0.0583 - lr: 6.0000e-04\nEpoch 27/250\n12500/12500 [==============================] - 65s 5ms/step - loss: 0.0594 - val_loss: 0.0584 - lr: 6.0000e-04\nEpoch 28/250\n12500/12500 [==============================] - 67s 5ms/step - loss: 0.0593 - val_loss: 0.0585 - lr: 6.0000e-04\nEpoch 29/250\n12500/12500 [==============================] - 67s 5ms/step - loss: 0.0592 - val_loss: 0.0584 - lr: 6.0000e-04\nEpoch 30/250\n12500/12500 [==============================] - 66s 5ms/step - loss: 0.0592 - val_loss: 0.0582 - lr: 6.0000e-04\nEpoch 31/250\n12500/12500 [==============================] - 65s 5ms/step - loss: 0.0591 - val_loss: 0.0602 - lr: 6.0000e-04\nEpoch 32/250\n12500/12500 [==============================] - 68s 5ms/step - loss: 0.0591 - val_loss: 0.0579 - lr: 6.0000e-04\nEpoch 33/250\n12500/12500 [==============================] - 68s 5ms/step - loss: 0.0590 - val_loss: 0.0584 - lr: 6.0000e-04\nEpoch 34/250\n12500/12500 [==============================] - 69s 6ms/step - loss: 0.0589 - val_loss: 0.0593 - lr: 6.0000e-04\nEpoch 35/250\n12500/12500 [==============================] - 68s 5ms/step - loss: 0.0589 - val_loss: 0.0583 - lr: 6.0000e-04\nEpoch 36/250\n12496/12500 [============================>.] - ETA: 0s - loss: 0.0588\nEpoch 00036: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\n12500/12500 [==============================] - 73s 6ms/step - loss: 0.0588 - val_loss: 0.0583 - lr: 6.0000e-04\nEpoch 37/250\n12500/12500 [==============================] - 69s 5ms/step - loss: 0.0582 - val_loss: 0.0593 - lr: 3.6000e-04\nEpoch 38/250\n12500/12500 [==============================] - 68s 5ms/step - loss: 0.0582 - val_loss: 0.0576 - lr: 3.6000e-04\nEpoch 39/250\n12500/12500 [==============================] - 65s 5ms/step - loss: 0.0581 - val_loss: 0.0577 - lr: 3.6000e-04\nEpoch 40/250\n12500/12500 [==============================] - 64s 5ms/step - loss: 0.0581 - val_loss: 0.0585 - lr: 3.6000e-04\nEpoch 41/250\n12500/12500 [==============================] - 67s 5ms/step - loss: 0.0581 - val_loss: 0.0577 - lr: 3.6000e-04\nEpoch 42/250\n12493/12500 [============================>.] - ETA: 0s - loss: 0.0580\nEpoch 00042: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.\n12500/12500 [==============================] - 65s 5ms/step - loss: 0.0580 - val_loss: 0.0584 - lr: 3.6000e-04\nEpoch 43/250\n12500/12500 [==============================] - 64s 5ms/step - loss: 0.0576 - val_loss: 0.0579 - lr: 2.1600e-04\nEpoch 44/250\n12500/12500 [==============================] - 64s 5ms/step - loss: 0.0576 - val_loss: 0.0574 - lr: 2.1600e-04\nEpoch 45/250\n12500/12500 [==============================] - 66s 5ms/step - loss: 0.0576 - val_loss: 0.0576 - lr: 2.1600e-04\nEpoch 46/250\n12500/12500 [==============================] - 70s 6ms/step - loss: 0.0576 - val_loss: 0.0579 - lr: 2.1600e-04\nEpoch 47/250\n12500/12500 [==============================] - 65s 5ms/step - loss: 0.0576 - val_loss: 0.0574 - lr: 2.1600e-04\nEpoch 48/250\n12497/12500 [============================>.] - ETA: 0s - loss: 0.0575\nEpoch 00048: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.\n12500/12500 [==============================] - 66s 5ms/step - loss: 0.0575 - val_loss: 0.0576 - lr: 2.1600e-04\nEpoch 49/250\n12500/12500 [==============================] - 65s 5ms/step - loss: 0.0573 - val_loss: 0.0573 - lr: 1.2960e-04\nEpoch 50/250\n12500/12500 [==============================] - 65s 5ms/step - loss: 0.0573 - val_loss: 0.0571 - lr: 1.2960e-04\nEpoch 51/250\n12500/12500 [==============================] - 66s 5ms/step - loss: 0.0572 - val_loss: 0.0573 - lr: 1.2960e-04\nEpoch 52/250\n12500/12500 [==============================] - 67s 5ms/step - loss: 0.0573 - val_loss: 0.0572 - lr: 1.2960e-04\nEpoch 53/250\n12500/12500 [==============================] - 67s 5ms/step - loss: 0.0572 - val_loss: 0.0574 - lr: 1.2960e-04\n","name":"stdout"},{"output_type":"stream","text":"Epoch 54/250\n12496/12500 [============================>.] - ETA: 0s - loss: 0.0572\nEpoch 00054: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.\n12500/12500 [==============================] - 69s 6ms/step - loss: 0.0572 - val_loss: 0.0576 - lr: 1.2960e-04\nEpoch 55/250\n12500/12500 [==============================] - 74s 6ms/step - loss: 0.0571 - val_loss: 0.0571 - lr: 7.7760e-05\nEpoch 56/250\n12500/12500 [==============================] - 68s 5ms/step - loss: 0.0571 - val_loss: 0.0570 - lr: 7.7760e-05\nEpoch 57/250\n12500/12500 [==============================] - 69s 6ms/step - loss: 0.0571 - val_loss: 0.0571 - lr: 7.7760e-05\nEpoch 58/250\n12498/12500 [============================>.] - ETA: 0s - loss: 0.0571\nEpoch 00058: ReduceLROnPlateau reducing learning rate to 4.6655999904032795e-05.\n12500/12500 [==============================] - 70s 6ms/step - loss: 0.0571 - val_loss: 0.0572 - lr: 7.7760e-05\nEpoch 59/250\n12500/12500 [==============================] - 72s 6ms/step - loss: 0.0570 - val_loss: 0.0571 - lr: 4.6656e-05\nEpoch 60/250\n12500/12500 [==============================] - 74s 6ms/step - loss: 0.0570 - val_loss: 0.0571 - lr: 4.6656e-05\nEpoch 61/250\n12500/12500 [==============================] - 71s 6ms/step - loss: 0.0570 - val_loss: 0.0570 - lr: 4.6656e-05\nEpoch 62/250\n12493/12500 [============================>.] - ETA: 0s - loss: 0.0570\nEpoch 00062: ReduceLROnPlateau reducing learning rate to 2.799360081553459e-05.\n12500/12500 [==============================] - 71s 6ms/step - loss: 0.0570 - val_loss: 0.0572 - lr: 4.6656e-05\nEpoch 63/250\n12500/12500 [==============================] - 70s 6ms/step - loss: 0.0569 - val_loss: 0.0570 - lr: 2.7994e-05\nEpoch 64/250\n12500/12500 [==============================] - 69s 6ms/step - loss: 0.0569 - val_loss: 0.0570 - lr: 2.7994e-05\nEpoch 65/250\n12500/12500 [==============================] - 68s 5ms/step - loss: 0.0569 - val_loss: 0.0570 - lr: 2.7994e-05\nEpoch 66/250\n12500/12500 [==============================] - 74s 6ms/step - loss: 0.0569 - val_loss: 0.0571 - lr: 2.7994e-05\nEpoch 67/250\n12495/12500 [============================>.] - ETA: 0s - loss: 0.0569\nEpoch 00067: ReduceLROnPlateau reducing learning rate to 1.6796160707599483e-05.\n12500/12500 [==============================] - 75s 6ms/step - loss: 0.0569 - val_loss: 0.0570 - lr: 2.7994e-05\nEpoch 68/250\n12500/12500 [==============================] - 79s 6ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 1.6796e-05\nEpoch 69/250\n12500/12500 [==============================] - 80s 6ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 1.6796e-05\nEpoch 70/250\n12500/12500 [==============================] - 76s 6ms/step - loss: 0.0569 - val_loss: 0.0570 - lr: 1.6796e-05\nEpoch 71/250\n12495/12500 [============================>.] - ETA: 0s - loss: 0.0569\nEpoch 00071: ReduceLROnPlateau reducing learning rate to 1.007769642455969e-05.\n12500/12500 [==============================] - 73s 6ms/step - loss: 0.0569 - val_loss: 0.0570 - lr: 1.6796e-05\nEpoch 72/250\n12500/12500 [==============================] - 77s 6ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 1.0078e-05\nEpoch 73/250\n12500/12500 [==============================] - 78s 6ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 1.0078e-05\nEpoch 74/250\n12500/12500 [==============================] - 74s 6ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 1.0078e-05\nEpoch 75/250\n12500/12500 [==============================] - ETA: 0s - loss: 0.0568\nEpoch 00075: ReduceLROnPlateau reducing learning rate to 6.046617636457085e-06.\n12500/12500 [==============================] - 74s 6ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 1.0078e-05\nEpoch 76/250\n12500/12500 [==============================] - 98s 8ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 6.0466e-06\nEpoch 77/250\n12500/12500 [==============================] - 82s 7ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 6.0466e-06\nEpoch 78/250\n12500/12500 [==============================] - 70s 6ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 6.0466e-06\nEpoch 79/250\n12492/12500 [============================>.] - ETA: 0s - loss: 0.0568\nEpoch 00079: ReduceLROnPlateau reducing learning rate to 3.6279706364439334e-06.\n12500/12500 [==============================] - 66s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 6.0466e-06\nEpoch 80/250\n12500/12500 [==============================] - 66s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 3.6280e-06\nEpoch 81/250\n12500/12500 [==============================] - 65s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 3.6280e-06\nEpoch 82/250\n12500/12500 [==============================] - 65s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 3.6280e-06\nEpoch 83/250\n12498/12500 [============================>.] - ETA: 0s - loss: 0.0568\nEpoch 00083: ReduceLROnPlateau reducing learning rate to 2.1767824364360423e-06.\n12500/12500 [==============================] - 66s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 3.6280e-06\nEpoch 84/250\n12500/12500 [==============================] - 65s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 2.1768e-06\nEpoch 85/250\n12500/12500 [==============================] - 65s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 2.1768e-06\nEpoch 86/250\n12500/12500 [==============================] - 66s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 2.1768e-06\nEpoch 87/250\n12492/12500 [============================>.] - ETA: 0s - loss: 0.0568\nEpoch 00087: ReduceLROnPlateau reducing learning rate to 1.3060694072919432e-06.\n12500/12500 [==============================] - 66s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 2.1768e-06\nEpoch 88/250\n12500/12500 [==============================] - 67s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 1.3061e-06\nEpoch 89/250\n12500/12500 [==============================] - 66s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 1.3061e-06\nEpoch 90/250\n12500/12500 [==============================] - 71s 6ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 1.3061e-06\nEpoch 91/250\n12493/12500 [============================>.] - ETA: 0s - loss: 0.0568\nEpoch 00091: ReduceLROnPlateau reducing learning rate to 7.836416443751659e-07.\n12500/12500 [==============================] - 69s 6ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 1.3061e-06\nEpoch 92/250\n12500/12500 [==============================] - 67s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 7.8364e-07\nEpoch 93/250\n12500/12500 [==============================] - 66s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 7.8364e-07\nEpoch 94/250\n12500/12500 [==============================] - 69s 6ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 7.8364e-07\nEpoch 95/250\n12499/12500 [============================>.] - ETA: 0s - loss: 0.0568\nEpoch 00095: ReduceLROnPlateau reducing learning rate to 4.701850002675201e-07.\n12500/12500 [==============================] - 70s 6ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 7.8364e-07\nEpoch 96/250\n12500/12500 [==============================] - 74s 6ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 4.7019e-07\nEpoch 97/250\n12500/12500 [==============================] - 70s 6ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 4.7019e-07\nEpoch 98/250\n12500/12500 [==============================] - 67s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 4.7019e-07\nEpoch 99/250\n12497/12500 [============================>.] - ETA: 0s - loss: 0.0568\nEpoch 00099: ReduceLROnPlateau reducing learning rate to 2.8211100016051206e-07.\n12500/12500 [==============================] - 67s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 4.7019e-07\nEpoch 100/250\n12500/12500 [==============================] - 71s 6ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 2.8211e-07\nEpoch 101/250\n12500/12500 [==============================] - 68s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 2.8211e-07\nEpoch 102/250\n12500/12500 [==============================] - 68s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 2.8211e-07\nEpoch 103/250\n12496/12500 [============================>.] - ETA: 0s - loss: 0.0568\nEpoch 00103: ReduceLROnPlateau reducing learning rate to 1.6926659327509696e-07.\n12500/12500 [==============================] - 67s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 2.8211e-07\nEpoch 104/250\n","name":"stdout"},{"output_type":"stream","text":"12500/12500 [==============================] - 68s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 1.6927e-07\nEpoch 105/250\n12500/12500 [==============================] - 64s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 1.6927e-07\nEpoch 106/250\n12500/12500 [==============================] - 64s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 1.6927e-07\nEpoch 107/250\n12493/12500 [============================>.] - ETA: 0s - loss: 0.0568\nEpoch 00107: ReduceLROnPlateau reducing learning rate to 1.0155995937566331e-07.\n12500/12500 [==============================] - 65s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 1.6927e-07\nEpoch 108/250\n12500/12500 [==============================] - 66s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 1.0156e-07\nEpoch 109/250\n12500/12500 [==============================] - 69s 6ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 1.0156e-07\nEpoch 110/250\n12500/12500 [==============================] - 66s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 1.0156e-07\nEpoch 111/250\n12490/12500 [============================>.] - ETA: 0s - loss: 0.0568\nEpoch 00111: ReduceLROnPlateau reducing learning rate to 6.093597733070056e-08.\n12500/12500 [==============================] - 67s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 1.0156e-07\nEpoch 112/250\n12500/12500 [==============================] - 67s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 6.0936e-08\nEpoch 113/250\n12500/12500 [==============================] - 65s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 6.0936e-08\nEpoch 114/250\n12500/12500 [==============================] - 68s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 6.0936e-08\nEpoch 115/250\n12499/12500 [============================>.] - ETA: 0s - loss: 0.0568\nEpoch 00115: ReduceLROnPlateau reducing learning rate to 3.656158469311776e-08.\n12500/12500 [==============================] - 64s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 6.0936e-08\nEpoch 116/250\n12500/12500 [==============================] - 65s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 3.6562e-08\nEpoch 117/250\n12500/12500 [==============================] - 66s 5ms/step - loss: 0.0568 - val_loss: 0.0570 - lr: 3.6562e-08\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Loss over epochs')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='best')\nplt.show()","execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 720x360 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"(550000, 30)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights(\"best_model.h5\")\n\ntest = X_test #convert pd to array\ntest = test.reshape(-1, 1,30)\n\n\npredictions = model.predict(test)","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(predictions.shape)\nprint(predictions)","execution_count":43,"outputs":[{"output_type":"stream","text":"(550000, 1)\n[[-0.01762744]\n [ 0.06913006]\n [ 0.36910522]\n ...\n [ 0.04759964]\n [ 0.37550092]\n [ 0.14360055]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('../input/higgs-boson/random_submission.zip')","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub","execution_count":37,"outputs":[{"output_type":"execute_result","execution_count":37,"data":{"text/plain":"        EventId  RankOrder Class\n0        350000     416957     b\n1        350001      89624     b\n2        350002     519845     b\n3        350003     510885     s\n4        350004     455944     s\n...         ...        ...   ...\n549995   899995      46701     s\n549996   899996     323731     s\n549997   899997     357749     s\n549998   899998     486844     b\n549999   899999     254659     b\n\n[550000 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EventId</th>\n      <th>RankOrder</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>350000</td>\n      <td>416957</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>350001</td>\n      <td>89624</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>350002</td>\n      <td>519845</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>350003</td>\n      <td>510885</td>\n      <td>s</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>350004</td>\n      <td>455944</td>\n      <td>s</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>549995</th>\n      <td>899995</td>\n      <td>46701</td>\n      <td>s</td>\n    </tr>\n    <tr>\n      <th>549996</th>\n      <td>899996</td>\n      <td>323731</td>\n      <td>s</td>\n    </tr>\n    <tr>\n      <th>549997</th>\n      <td>899997</td>\n      <td>357749</td>\n      <td>s</td>\n    </tr>\n    <tr>\n      <th>549998</th>\n      <td>899998</td>\n      <td>486844</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>549999</th>\n      <td>899999</td>\n      <td>254659</td>\n      <td>b</td>\n    </tr>\n  </tbody>\n</table>\n<p>550000 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(predictions)","execution_count":38,"outputs":[{"output_type":"execute_result","execution_count":38,"data":{"text/plain":"numpy.ndarray"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = np.where(predictions > 0.5, 1, 0)\npred","execution_count":40,"outputs":[{"output_type":"execute_result","execution_count":40,"data":{"text/plain":"array([[0],\n       [0],\n       [0],\n       ...,\n       [0],\n       [0],\n       [0]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predict = pd.Series(pred[:,0])","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predict","execution_count":45,"outputs":[{"output_type":"execute_result","execution_count":45,"data":{"text/plain":"0         0\n1         0\n2         0\n3         1\n4         0\n         ..\n549995    0\n549996    0\n549997    0\n549998    0\n549999    0\nLength: 550000, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predict = pd.DataFrame({\"EventId\":sub['EventId'],\"RankOrder\":sub['RankOrder'],\"Class\":test_predict})\ntest_predict","execution_count":46,"outputs":[{"output_type":"execute_result","execution_count":46,"data":{"text/plain":"        EventId  RankOrder  Class\n0        350000     416957      0\n1        350001      89624      0\n2        350002     519845      0\n3        350003     510885      1\n4        350004     455944      0\n...         ...        ...    ...\n549995   899995      46701      0\n549996   899996     323731      0\n549997   899997     357749      0\n549998   899998     486844      0\n549999   899999     254659      0\n\n[550000 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EventId</th>\n      <th>RankOrder</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>350000</td>\n      <td>416957</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>350001</td>\n      <td>89624</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>350002</td>\n      <td>519845</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>350003</td>\n      <td>510885</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>350004</td>\n      <td>455944</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>549995</th>\n      <td>899995</td>\n      <td>46701</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>549996</th>\n      <td>899996</td>\n      <td>323731</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>549997</th>\n      <td>899997</td>\n      <td>357749</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>549998</th>\n      <td>899998</td>\n      <td>486844</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>549999</th>\n      <td>899999</td>\n      <td>254659</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>550000 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predict = test_predict.replace(1,'s')\ntest_predict = test_predict.replace(0,'b')\ntest_predict","execution_count":47,"outputs":[{"output_type":"execute_result","execution_count":47,"data":{"text/plain":"        EventId RankOrder Class\n0        350000    416957     b\n1        350001     89624     b\n2        350002    519845     b\n3        350003    510885     s\n4        350004    455944     b\n...         ...       ...   ...\n549995   899995     46701     b\n549996   899996    323731     b\n549997   899997    357749     b\n549998   899998    486844     b\n549999   899999    254659     b\n\n[550000 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EventId</th>\n      <th>RankOrder</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>350000</td>\n      <td>416957</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>350001</td>\n      <td>89624</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>350002</td>\n      <td>519845</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>350003</td>\n      <td>510885</td>\n      <td>s</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>350004</td>\n      <td>455944</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>549995</th>\n      <td>899995</td>\n      <td>46701</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>549996</th>\n      <td>899996</td>\n      <td>323731</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>549997</th>\n      <td>899997</td>\n      <td>357749</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>549998</th>\n      <td>899998</td>\n      <td>486844</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>549999</th>\n      <td>899999</td>\n      <td>254659</td>\n      <td>b</td>\n    </tr>\n  </tbody>\n</table>\n<p>550000 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predict['RankOrder'] = test_predict['Class'].argsort().argsort() + 1 # +1 to start at 1","execution_count":48,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predict","execution_count":49,"outputs":[{"output_type":"execute_result","execution_count":49,"data":{"text/plain":"        EventId  RankOrder Class\n0        350000          1     b\n1        350001     383328     b\n2        350002     383322     b\n3        350003     405793     s\n4        350004     383320     b\n...         ...        ...   ...\n549995   899995     155432     b\n549996   899996     155431     b\n549997   899997     155430     b\n549998   899998     106192     b\n549999   899999     233160     b\n\n[550000 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EventId</th>\n      <th>RankOrder</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>350000</td>\n      <td>1</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>350001</td>\n      <td>383328</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>350002</td>\n      <td>383322</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>350003</td>\n      <td>405793</td>\n      <td>s</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>350004</td>\n      <td>383320</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>549995</th>\n      <td>899995</td>\n      <td>155432</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>549996</th>\n      <td>899996</td>\n      <td>155431</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>549997</th>\n      <td>899997</td>\n      <td>155430</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>549998</th>\n      <td>899998</td>\n      <td>106192</td>\n      <td>b</td>\n    </tr>\n    <tr>\n      <th>549999</th>\n      <td>899999</td>\n      <td>233160</td>\n      <td>b</td>\n    </tr>\n  </tbody>\n</table>\n<p>550000 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predict.to_csv(\"submission.csv\",index=False)","execution_count":50,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}